# è¯­éŸ³è¯†åˆ«é›†æˆæ–¹æ¡ˆ

## å½“å‰çŠ¶æ€

âŒ **ä¸æ”¯æŒçœŸå®è¯­éŸ³è¯†åˆ«** - åªèƒ½æ–‡æœ¬è¾“å…¥ï¼ˆ`input()`ï¼‰

---

## ä¸‰ç§é›†æˆæ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | éš¾åº¦ | æ—¶é—´ | å‡†ç¡®ç‡ | ç¦»çº¿ | æ¨èåº¦ |
|------|------|------|--------|------|--------|
| **macOS å¬å†™ API** | â­ ç®€å• | 20 åˆ†é’Ÿ | 80% | âŒ éœ€è”ç½‘ | â­â­â­â­ |
| **Whisper (CPU)** | â­â­ ä¸­ç­‰ | 1 å°æ—¶ | 95% | âœ… ç¦»çº¿ | â­â­â­â­â­ |
| **å½•éŸ³ + äº‘ API** | â­â­â­ å¤æ‚ | 2 å°æ—¶ | 90% | âŒ éœ€è”ç½‘ | â­â­â­ |

---

## ğŸš€ æ–¹æ¡ˆä¸€ï¼šmacOS ç³»ç»Ÿå¬å†™ï¼ˆæœ€å¿«ï¼‰

### ä¼˜ç‚¹
- âœ… æ— éœ€å®‰è£…é¢å¤–ä¾èµ–
- âœ… æ”¯æŒä¸­æ–‡
- âœ… ç³»ç»Ÿçº§ä¼˜åŒ–ï¼Œé€Ÿåº¦å¿«
- âœ… 20 åˆ†é’Ÿå³å¯å®Œæˆ

### ç¼ºç‚¹
- âš ï¸ éœ€è¦åœ¨ç³»ç»Ÿè®¾ç½®ä¸­å¯ç”¨å¬å†™åŠŸèƒ½
- âš ï¸ éœ€è¦è”ç½‘ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
- âš ï¸ å‡†ç¡®ç‡ä¸€èˆ¬ï¼ˆ~80%ï¼‰

### å®ç°ä»£ç 

```python
# app/asr.py (æ›¿æ¢ç°æœ‰ä»£ç )

import subprocess
import tempfile
import os
from pathlib import Path

class MacOSDictationASR:
    """ä½¿ç”¨ macOS ç³»ç»Ÿå¬å†™çš„ ASR å¼•æ“"""

    def __init__(self):
        self.mode = "macos_dictation"
        logger.info(f"ASR initialized in mode: {self.mode}")
        self._check_dictation_enabled()

    def _check_dictation_enabled(self):
        """æ£€æŸ¥ç³»ç»Ÿå¬å†™æ˜¯å¦å¯ç”¨"""
        # å¯ä»¥é€šè¿‡ AppleScript æ£€æŸ¥
        script = '''
        tell application "System Events"
            return "System dictation is available"
        end tell
        '''
        try:
            subprocess.run(["osascript", "-e", script], check=True)
            logger.info("âœ… macOS dictation is available")
        except:
            logger.warning("âš ï¸ macOS dictation may need to be enabled in System Preferences")

    def transcribe_once(self) -> Optional[str]:
        """ä½¿ç”¨ macOS å¬å†™å½•éŸ³å¹¶è½¬æ–‡å­—"""
        try:
            print("\nğŸ¤ è¯·è¯´è¯ï¼ˆæŒ‰ Fn é”®ä¸¤æ¬¡å¼€å§‹å¬å†™ï¼‰...")

            # æ–¹æ³• 1: ä½¿ç”¨ AppleScript è§¦å‘ç³»ç»Ÿå¬å†™
            # è¿™ä¼šæ‰“å¼€å¬å†™ç•Œé¢ï¼Œç”¨æˆ·è¯´è¯åè‡ªåŠ¨è½¬æ–‡å­—
            script = '''
            tell application "System Events"
                keystroke "x" using {function down, function down}
            end tell
            '''

            # è¿™é‡Œéœ€è¦ç”¨æˆ·æ‰‹åŠ¨è§¦å‘å¬å†™
            # æ›´å¥½çš„æ–¹æ¡ˆæ˜¯ä¸‹é¢çš„æ–¹æ³• 2

            print("æç¤ºï¼šåœ¨ macOS ä¸­æŒ‰ Fn é”®ä¸¤æ¬¡æ¿€æ´»å¬å†™")
            print("æˆ–è€…ä½¿ç”¨ä¸‹é¢çš„ Whisper æ–¹æ¡ˆå®ç°çœŸæ­£çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«")

            # ç›®å‰ä»ä½¿ç”¨æ–‡æœ¬è¾“å…¥ä½œä¸ºå›é€€
            text = input("æˆ–ç›´æ¥è¾“å…¥æ–‡å­—: ").strip()

            if text and text.lower() not in ["exit", "quit", "é€€å‡º"]:
                logger.info(f"ASR transcribed: {text}")
                return text

            return None

        except Exception as e:
            logger.error(f"ASR error: {e}")
            return None
```

### å¯ç”¨æ­¥éª¤
1. ç³»ç»Ÿè®¾ç½® â†’ é”®ç›˜ â†’ å¬å†™ â†’ å¼€å¯
2. è¿è¡Œç¨‹åº
3. æŒ‰ Fn é”®ä¸¤æ¬¡å¼€å§‹è¯´è¯

### é™åˆ¶
- éœ€è¦ç”¨æˆ·æ‰‹åŠ¨è§¦å‘å¬å†™ï¼ˆæ— æ³•å®Œå…¨è‡ªåŠ¨åŒ–ï¼‰
- æ›´é€‚åˆä½œä¸ºè¾…åŠ©æ–¹æ¡ˆ

---

## ğŸ¯ æ–¹æ¡ˆäºŒï¼šWhisperï¼ˆæ¨èï¼ï¼‰â­â­â­â­â­

### ä¼˜ç‚¹
- âœ… å‡†ç¡®ç‡æé«˜ï¼ˆ95%+ï¼‰
- âœ… å®Œå…¨ç¦»çº¿
- âœ… æ”¯æŒä¸­è‹±æ–‡æ··åˆ
- âœ… è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜
- âœ… åœ¨ Mac M1/M2 ä¸Šé€Ÿåº¦å¿«

### ç¼ºç‚¹
- âš ï¸ é¦–æ¬¡éœ€è¦ä¸‹è½½æ¨¡å‹ï¼ˆ~150MBï¼‰
- âš ï¸ éœ€è¦å®‰è£…ä¾èµ–

### å®‰è£…æ­¥éª¤

```bash
# 1. å®‰è£…éŸ³é¢‘å¤„ç†åº“
pip install pyaudio faster-whisper

# 2. å¦‚æœ pyaudio å®‰è£…å¤±è´¥ï¼Œç”¨ brew
brew install portaudio
pip install pyaudio
```

### å®ç°ä»£ç 

```python
# app/asr_whisper.py (æ–°æ–‡ä»¶)

import wave
import pyaudio
from faster_whisper import WhisperModel
from pathlib import Path
import tempfile

class WhisperASR:
    """åŸºäº Faster Whisper çš„ ASR å¼•æ“"""

    def __init__(self, model_size="base"):
        """
        åˆå§‹åŒ– Whisper ASR

        Args:
            model_size: tiny/base/small/medium/large
                       base æ¨èï¼ˆé€Ÿåº¦å¿«ï¼Œå‡†ç¡®ç‡é«˜ï¼‰
        """
        self.mode = "whisper"
        print(f"ğŸ¤ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ï¼ˆ{model_size}ï¼‰...")

        # åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
        self.model = WhisperModel(
            model_size,
            device="cpu",  # Mac M1/M2 å¯ä»¥ç”¨ "auto"
            compute_type="int8"  # é‡åŒ–åŠ é€Ÿ
        )

        # å½•éŸ³å‚æ•°
        self.sample_rate = 16000
        self.chunk_size = 1024
        self.channels = 1

        logger.info(f"âœ… Whisper ASR initialized")

    def record_audio(self, duration=5):
        """
        å½•éŸ³æŒ‡å®šç§’æ•°

        Args:
            duration: å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰

        Returns:
            éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        print(f"ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆ{duration}ç§’ï¼‰...")

        # PyAudio å½•éŸ³
        p = pyaudio.PyAudio()
        stream = p.open(
            format=pyaudio.paInt16,
            channels=self.channels,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size
        )

        frames = []
        for i in range(0, int(self.sample_rate / self.chunk_size * duration)):
            data = stream.read(self.chunk_size)
            frames.append(data)

        stream.stop_stream()
        stream.close()
        p.terminate()

        # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        wf = wave.open(temp_file.name, 'wb')
        wf.setnchannels(self.channels)
        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
        wf.setframerate(self.sample_rate)
        wf.writeframes(b''.join(frames))
        wf.close()

        print("âœ… å½•éŸ³å®Œæˆ")
        return temp_file.name

    def transcribe_once(self, duration=5) -> Optional[str]:
        """
        å½•éŸ³å¹¶è½¬æ–‡å­—

        Args:
            duration: å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰

        Returns:
            è½¬å½•æ–‡æœ¬
        """
        try:
            # 1. å½•éŸ³
            audio_file = self.record_audio(duration)

            # 2. è½¬å½•
            print("ğŸ¤– æ­£åœ¨è¯†åˆ«...")
            segments, info = self.model.transcribe(
                audio_file,
                language="zh",  # ä¸­æ–‡
                beam_size=5
            )

            # 3. åˆå¹¶æ‰€æœ‰ç‰‡æ®µ
            text = "".join([seg.text for seg in segments]).strip()

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            Path(audio_file).unlink()

            if text:
                print(f"âœ… è¯†åˆ«ç»“æœ: {text}")
                logger.info(f"ASR transcribed: {text}")
                return text
            else:
                print("âš ï¸ æœªè¯†åˆ«åˆ°å†…å®¹")
                return None

        except KeyboardInterrupt:
            print("\nâš ï¸ å·²å–æ¶ˆ")
            return None
        except Exception as e:
            logger.error(f"ASR error: {e}")
            print(f"âŒ è¯†åˆ«å¤±è´¥: {e}")
            return None

    def transcribe_until_silence(self):
        """
        æŒç»­å½•éŸ³ç›´åˆ°æ£€æµ‹åˆ°é™éŸ³
        ï¼ˆé«˜çº§åŠŸèƒ½ï¼Œéœ€è¦ VADï¼‰
        """
        # TODO: å®ç° Voice Activity Detection
        pass


def create_asr_engine(engine="whisper"):
    """
    åˆ›å»º ASR å¼•æ“

    Args:
        engine: "whisper" | "text" | "macos"
    """
    if engine == "whisper":
        return WhisperASR(model_size="base")
    elif engine == "text":
        from .asr import ASREngine
        return ASREngine()  # æ–‡æœ¬è¾“å…¥æ¨¡å¼
    else:
        raise ValueError(f"Unknown engine: {engine}")
```

### ä½¿ç”¨æ–¹æ³•

```python
# åœ¨ main.py ä¸­ä¿®æ”¹

# åˆ›å»º Whisper ASR
from app.asr_whisper import WhisperASR
asr = WhisperASR(model_size="base")

# å½•éŸ³ 5 ç§’å¹¶è¯†åˆ«
text = asr.transcribe_once(duration=5)
print(f"ä½ è¯´: {text}")
```

### æ¨¡å‹é€‰æ‹©

| æ¨¡å‹ | å¤§å° | é€Ÿåº¦ | å‡†ç¡®ç‡ | æ¨è |
|------|------|------|--------|------|
| tiny | 39 MB | æœ€å¿« | 70% | âŒ |
| base | 74 MB | å¿« | 85% | âœ… æ¨è |
| small | 244 MB | ä¸­ | 90% | â­ å¹³è¡¡ |
| medium | 769 MB | æ…¢ | 95% | é«˜ç²¾åº¦ |

---

## ğŸ”§ æ–¹æ¡ˆä¸‰ï¼šå½•éŸ³ + OpenAI Whisper API

### ä¼˜ç‚¹
- âœ… å‡†ç¡®ç‡æœ€é«˜
- âœ… æ— éœ€æœ¬åœ°æ¨¡å‹
- âœ… æ”¯æŒå¤šè¯­è¨€

### ç¼ºç‚¹
- âŒ éœ€è¦è”ç½‘
- âŒ éœ€è¦ API Key
- âŒ æœ‰è´¹ç”¨ï¼ˆ$0.006/åˆ†é’Ÿï¼‰

### å®ç°ä»£ç 

```python
import openai
import pyaudio
import wave

class OpenAIWhisperASR:
    def __init__(self, api_key):
        openai.api_key = api_key
        self.mode = "openai_whisper"

    def transcribe_once(self, duration=5):
        # 1. å½•éŸ³ï¼ˆåŒæ–¹æ¡ˆäºŒï¼‰
        audio_file = self.record_audio(duration)

        # 2. è°ƒç”¨ OpenAI API
        with open(audio_file, "rb") as f:
            transcript = openai.Audio.transcribe("whisper-1", f)

        return transcript["text"]
```

---

## ğŸ“Š æ¨èæµç¨‹

### ç¬¬ 1 æ­¥ï¼šå¿«é€Ÿä½“éªŒï¼ˆ5 åˆ†é’Ÿï¼‰
ä¿æŒå½“å‰çš„æ–‡æœ¬è¾“å…¥æ¨¡å¼ï¼Œå…ˆæŠŠå…¶ä»–åŠŸèƒ½å®Œå–„

### ç¬¬ 2 æ­¥ï¼šç”Ÿäº§çº§è¯­éŸ³ï¼ˆ1 å°æ—¶ï¼‰
é›†æˆ Faster Whisperï¼Œå®ç°çœŸæ­£çš„è¯­éŸ³è¯†åˆ«

### ç¬¬ 3 æ­¥ï¼šä¼˜åŒ–ä½“éªŒï¼ˆå¯é€‰ï¼‰
- VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰è‡ªåŠ¨å¼€å§‹/åœæ­¢å½•éŸ³
- èƒŒæ™¯å™ªéŸ³æ¶ˆé™¤
- å”¤é†’è¯æ£€æµ‹

---

## âš¡ ç«‹å³å®ç° Whisper

å¦‚æœä½ æƒ³ç«‹å³å®ç°çœŸå®è¯­éŸ³è¯†åˆ«ï¼Œè¿è¡Œï¼š

```bash
# 1. å®‰è£…ä¾èµ–
pip install pyaudio faster-whisper

# 2. åˆ›å»ºæ–°æ–‡ä»¶
# (å‚è€ƒä¸Šé¢çš„ app/asr_whisper.py ä»£ç )

# 3. ä¿®æ”¹ main.py
# from app.asr import create_asr_engine  # æ—§çš„
# from app.asr_whisper import WhisperASR  # æ–°çš„

# 4. æµ‹è¯•
python -c "from app.asr_whisper import WhisperASR; asr = WhisperASR(); text = asr.transcribe_once(3); print(text)"
```

---

## âœ… é€‰æ‹©å»ºè®®

| ä½ çš„ç›®æ ‡ | æ¨èæ–¹æ¡ˆ | ç†ç”± |
|----------|----------|------|
| **å¿«é€Ÿæ¼”ç¤ºé¡¹ç›®** | ä¿æŒæ–‡æœ¬è¾“å…¥ | ä¸è€½è¯¯å…¶ä»–åŠŸèƒ½å¼€å‘ |
| **çœŸå®äº§å“** | Whisper (æ–¹æ¡ˆäºŒ) | å‡†ç¡®ç‡é«˜ã€ç¦»çº¿ã€å¼€æº |
| **æœ€é«˜ç²¾åº¦** | OpenAI API (æ–¹æ¡ˆä¸‰) | äº‘ç«¯æœ€å¼ºï¼Œä½†æœ‰æˆæœ¬ |

---

## ğŸ¯ æˆ‘çš„å»ºè®®

1. **ç°åœ¨**ï¼šä¿æŒæ–‡æœ¬è¾“å…¥ï¼Œä¼˜å…ˆå®Œæˆå¤šæ­¥éª¤ç»„åˆå’Œå†…å®¹åˆ›ä½œåŠŸèƒ½
2. **ç„¶å**ï¼šèŠ± 1 å°æ—¶é›†æˆ Faster Whisper
3. **æœ€å**ï¼šä¼˜åŒ–å½•éŸ³ä½“éªŒï¼ˆVADã€é™å™ªç­‰ï¼‰

è¿™æ ·èƒ½ç¡®ä¿æ ¸å¿ƒåŠŸèƒ½å®Œæ•´ï¼ŒåŒæ—¶ä¹Ÿæœ‰çœŸå®çš„è¯­éŸ³èƒ½åŠ›ï¼

---

**éœ€è¦æˆ‘å¸®ä½ ç«‹å³å®ç° Whisper è¯­éŸ³è¯†åˆ«å—ï¼Ÿ**
